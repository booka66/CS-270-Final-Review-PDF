\documentclass[10pt]{report}

\input{helpers/preamble}
\input{helpers/macros}
\input{helpers/letterfonts}

\usepackage{graphicx}
\usepackage{blkarray}

\title{\Huge{CS 270}\\Final Exam Review}
\author{\huge{Jake Cahoon}}
\date{}

\begin{document}

\maketitle
\newpage
\pdfbookmark[section]{\contentsname}{toc}
\renewcommand{\contentsname}{Table of Contents}
\tableofcontents
\pagebreak

\chapter{Introduction}
\section{Note From Jake}
I hope the last review document was helpful, and I hope this one is as well. To make these, I've gone through the Exam Study Guide topics posted on Learning Suite. With the hope that I don't miss topics that will be on the final, I went through every slide and included all that I deem noteworthy. Despite this endeavor, I will miss topics, so I suggest you use this as a supplement to your study rather than relying solely on it.

I've included a table of contents this time around, so you can jump to the topics you need to study. That being said, let's friggin' do this.

\pagebreak

\chapter{Data Mining Process Model}
\section{The Process}
\nt{I'm pulling straight from the slides here. Know this process at a high level.}
\begin{enumerate}
  \item Identify and define the task (business understanding)
    \begin{itemize}
      \item Understand the context, audience, and problem
      \item Tell the story
    \end{itemize}
  \item Gather and prepare the data
    \begin{itemize}
      \item Build a dataset for the task
      \item Select/transform/derive features
      \item Conduct exploratory data analysis
      \item Clean the data
    \end{itemize}
  \item Build and evaluate model
  \item Deploy the model
    \begin{itemize}
      \item Evaluate business related results
    \end{itemize}
  \item Iterate and improve the model
\end{enumerate}
\section{The Cycle Picture}
\includegraphics[width=\textwidth]{images/cycle.png}

\chapter{Bayesian Learning}
There are two approaches to statistical learning: frequentist and Bayesian. Frequentist statistics is based on the idea of repeated sampling, while Bayesian statistics is based on the idea of starting with prior beliefs and then updating beliefs based on new information.
\section{Bayes Theorem}
\dfn{}{
  Let $C$ and $A$ be events. Then
  \begin{align*}
    P(C|A) &= \frac{P(A|C)P(C)}{P(A)}
  \end{align*}
  \nt{The right side of the equation is based on our current data, while the left side is what we want to find.}
}
\subsection{Notes}
\begin{itemize}
  \item Prior probabilities are based on prior knowledge. They are the initial beliefs.
    \item Posterior probabilities are the updated beliefs based on new information.
  \item $P(C)$ is the prior probability of the Class.
  \item $P(A)$ is the prior probability of the Attribute.
  \item $P(A|C)$ is the likelihood of the Attribute given the Class.
  \item $P(C|A)$ is the posterior probability of the Class given the Attribute.
\end{itemize}
\section{Bayesian Classifiers}
Given a set of attributes $\{A_1, A_2, \ldots, A_n\}$ and a class $C$, we can use Bayes Theorem to find the output class $C$ that maximizes $P(C | A_1, A_2, \ldots, A_n)$. For each output class $C$, do
\begin{align*}
  P(C | A_1, A_2, \ldots, A_n) &= \frac{P(A_1, A_2, \ldots, A_n | C)P(C)}{P(A_1, A_2, \ldots, A_n)}
\end{align*}
\section{Maximum A Posteriori (MAP) Estimation}
\dfn{}{
  Let $D$ be a dataset and let $H$ be the set of all hypotheses. Then
  \begin{align*}
    \hat{h}_{MAP} &= \argmax_{h\in H} P(h|D)\\
  \end{align*}
  where $\hat{h}_{MAP}$ is the maximum a posteriori hypothesis.
}
This is guaranteed to be ``best'', but it is computationally expensive and impractical for large hypothesis spaces.
\section{Bayes Optimal Classifier}
% TODO: I have no idea what to add here.
TODO: Figure out what to add here.
\section{Naive Bayes Classifiers}
A simple classifier that assumes that the attributes are conditionally independent given the class. This is a naive assumption, but it works well in practice. We assume that:
\begin{align*}
  P(A_1, A_2, \ldots A_n | C) &= P(A_1 | C) \cdot P(A_2 | C) \cdot \ldots \cdot P(A_n | C)
\end{align*}
In other words, the probability of all the attributes given the class is the product of the probabilities of each attribute given the class. Then for each $A_i \in A$ and for each $C_j \in C$ we can estimate $P(A_i | C_j)$, which you did when you calculated the probabilities in the HW.

Once we have the probabilities, we can classify a new instance $X$ by
\begin{align*}
  \hat{C} &= \argmax_{C_j \in C} \left(P(C_j) \cdot \prod_{i=1}^n P(A_i | C_j)\right)
\end{align*}
\subsection{Notes}
\begin{itemize}
  \item Various $P(C_j)$ and $P(A_i | C_j)$ are estimated from the training data.
  \item Stores the probabilities in a table.
  \item For a new instance $X$, the classifier calculates the probability of each class given the attributes.
  \item $\hat{C}$ is the class with the highest probability.
  \item The true probability is the normalized probability.
  \item Independence assumption may not hold for some attributes.
\end{itemize}

\chapter{Ensembles}
\begin{quote}
  Two heads are better than one, not because either is infallible, but because they are unlikely to go wrong in the same direction. - C.S. Lewis
\end{quote}
\section{Bias and Variance}
\begin{itemize}
  \item Bias is the error due to overly simplistic assumptions in the learning algorithm.
  \item Variance is the error due to the algorithm's sensitivity to fluctuations in the training data.
\end{itemize}
Bias and variance are inversely related. As one goes up, the other goes down. The goal is to minimize both.
\section{Why are Ensembles Helpful?}
By using ensembles, we can reduce the bias and variance of our models. Ensembles combine multiple models to create a stronger model. The idea is that the models will make different errors, and by combining them, we can reduce the overall error. See Dr. Snell's slides for examples.
\subsection{Four Important Criteria}
\begin{enumerate}
  \item \textit{Independence:} The models should be independent.
  \item \textit{Diversity:} The models should be different enough to make different errors.
  \item \textit{Decentralization:} The models should be trained on different subsets of the data.
  \item \textit{Aggregation:} The models should be combined in a way that reduces error.
\end{enumerate}
\section{Voting Ensemble}
Let $T$ be the training set, $A = \{A_1, A_2, \ldots, A_n\}$ be the set of models, and $C$ be the set of classes. Define a function $\delta$ as follows:
\begin{align*}
  \delta(a, b) &= \begin{cases}
    1 & \text{if } a = b\\
    0 & \text{otherwise}
  \end{cases}
\end{align*}
Then the voting ensemble is defined as
\begin{enumerate}
  \item For $k = 1$ to $N$, $h_k$ is a model trained on $T$ using learning algorithm $A_k$.
  \item For a new instance $X$, the ensemble predicts
    \begin{align*}
      \hat{C} &= \argmax_{c \in C} \sum_{k=1}^N \delta(c, h_k(X))
    \end{align*}
\end{enumerate}
\subsection{Notes}
\begin{itemize}
  \item Key issues: diversity and independence (too small of a set $A$ and too similar models will not help).
  \item The models should be trained on different subsets of the data.
\end{itemize}
\section{Bagging}
Let $T$ be the training set, $A$ be the learning algorithm, $N$ be the number of samples (or bags) of size $d$ drawn from $T$, $C$ be the set of classes, and $\delta$ be defined as in the Voting Ensembles section. Then the bagging ensemble is defined as
\begin{enumerate}
  \item For $k = 1$ to $N$, $S_k \subseteq T$ is a sample of size $d$ drawn from $T$, with replacement and $h_k$ is a model trained on $S_k$ using learning algorithm $A$.
    \item For a new instance $X$, the ensemble predicts
      \begin{align*}
        \hat{C} &= \argmax_{c \in C} \sum_{k=1}^N \delta(c, h_k(X))
      \end{align*}
\end{enumerate}
\subsection{Random Forest}
\begin{itemize}
  \item A bagging ensemble extension of decision trees
  \item Each tree is trained on a different bootstrap sample
  \item Two random variables: the bootstrap sample and the feature subset
\end{itemize}
\subsection{Notes}
\begin{itemize}
  \item Train $N$ models on $N$ different bootstrap samples
  \item Combines the outputs by voting ($\delta$ function)
  \item Decreases error by reducing variance due to unstable learning algorithms
  \item Homogeneous models are used
\end{itemize}
\begin{align*}
  \includegraphics[width=0.75\textwidth]{images/bagging.png}
\end{align*}
\section{Boosting}
``Boost weak learners into strong learners.''
\subsection{AdaBoost}
AdaBoost learns from mistakes by increasing the weights of the misclassified instances.
His slides go quite in depth on AdaBoost (adaptive boosting), so I would recommend reviewing them.
\begin{enumerate}
  \item Start with uniform weights
  \item Train a weak learner
  \item Update the weigthts based on the performance of the weak learner
  \item Repeat
\end{enumerate}
\subsection{Gradient Boosting}
Unlike AdaBoost, Gradient Boosting learns from residual errors, rather than directly updating the weights.
\begin{enumerate}
  \item Train a weak learner
  \item Compute the residuals (errors) on the training set
  \item Train a new weak learner to predict the residuals
  \item Repeat from step 2 until the residuals are small
\end{enumerate}
\subsection{Notes}
\begin{itemize}
  \item Great for reducing bias
  \item Combines the outputs by weighted voting/averaging
  \item Homogeneous models are used
  \item Weak learners need to be better than random guessing
  \item Construct a strong learner by weighted voting of the weak learners
\end{itemize}
\begin{align*}
  \includegraphics[width=0.75\textwidth]{images/boosting.png}
\end{align*}
\section{Stacking}
Let $T$ be the base-level training set, $N$ be the number of base-level learning algorithms, $A = \{A_1, A_2, \ldots, A_n, A_{\text{meta}}\}$ be the set of base-level learning algorithms, and $A_{\text{meta}}$ be the chosen meta-level learner.
Then the stacking ensemble is defined as
\begin{enumerate}
  \item For $i = 1$ to $N$, $h_i$ is a model trained on $T$ using learning algorithm $A_i$.
  \item Let $T_m$ be the meta-level training set. $T_m = \emptyset$.
  \item For $k = 1$ to $|T|$, $E_k = \{h_1(X_k), h_2(X_k), \ldots, h_N(X_k), y_k\}$.
  \item $T_m = T_m \cup E_k$.
  \item $h_{\text{meta}}$ is a model trained on $T_m$ using learning algorithm $A_{\text{meta}}$.
  \item For a new instance $X$, the ensemble predicts
      \begin{align*}
        \hat{C} &= h_{\text{meta}}(h_1(X), h_2(X), \ldots, h_N(X))
      \end{align*}
\end{enumerate}
\subsection{Notes}
\begin{itemize}
  \item Improves accuracy by combining the outputs of multiple models
  \item Hetereogeneous models are used at the base level
  \item The meta-level model is trained on the outputs of the base-level models
\end{itemize}
\begin{align*}
  \includegraphics[width=0.75\textwidth]{images/stacking.png}
\end{align*}

\chapter{Clustering}
Clustering is an important type of unsupervised learning (PCA is unsupervised). The goal of clustering is to group similar data points together in a cluster.

\section{K-Means}
K-Means is a simple and popular clustering algorithm. The goal is to partition the data into $k$ clusters. The algorithm works as follows:
\section{Hierarchical Clustering}
\begin{enumerate}
  \item Start with an $n \times n$ adjacency matrix
  \item Initialize each point as its own cluster
  \item Merge the two ``closest'' clusters (closeness is either single, complete, or average linkage)
  \item Repeat until there is only one cluster
\end{enumerate}
\subsection{Walkthrough}
\ex{}{
  Compute the clusters for the following adjacency matrix using single linkage.
  \begin{align*}
    \begin{blockarray}{cccccc}
      & a & b & c & d & e \\
      \begin{block}{c[ccccc]}
        a & 0 & 1.4 & 0.2 & 1.3 & 1.2 \\
        b & 1.4 & 0 & 1.6 & 0.1 & 0.4 \\
        c & 0.2 & 1.6 & 0 & 1.5 & 1.4 \\
        d & 1.3 & 0.1 & 1.5 & 0 & 0.3 \\
        e & 1.2 & 0.4 & 1.4 & 0.3 & 0 \\
      \end{block}
    \end{blockarray}
  \end{align*}
  \nt{I recommend x-ing out the values in the clusters you've already merged.}
}
\sol{}{
  \begin{enumerate}
    \item Merge: $b$ and $d$ since the distance between them is $0.1$.
      \begin{align*}
        \begin{blockarray}{cccccc}
          & a & b & c & d & e \\
          \begin{block}{c[ccccc]}
            a & 0 & 1.4 & 0.2 & 1.3 & 1.2 \\
            b & 1.4 & 0 & 1.6 & 0.1 & 0.4 \\
            c & 0.2 & 1.6 & 0 & 1.5 & 1.4 \\
            d & 1.3 & 0.1 & 1.5 & 0 & 0.3 \\
            e & 1.2 & 0.4 & 1.4 & 0.3 & 0 \\
          \end{block}
        \end{blockarray}
        \quad
        \implies
        \quad
        \begin{blockarray}{cccccc}
          & a & b & c & d & e \\
          \begin{block}{c[ccccc]}
            a & 0 & 1.4 & 0.2 & 1.3 & 1.2 \\
            b & 1.4 & 0 & 1.6 & \boxed{0.1} & 0.4 \\
            c & 0.2 & 1.6 & 0 & 1.5 & 1.4 \\
            d & 1.3 & \boxed{0.1} & 1.5 & 0 & 0.3 \\
            e & 1.2 & 0.4 & 1.4 & 0.3 & 0 \\
          \end{block}
        \end{blockarray}
      \end{align*}
    \item Merge: $a$ and $c$ since the distance between them is $0.2$.
      \begin{align*}
        \begin{blockarray}{cccccc}
          & a & b & c & d & e \\
          \begin{block}{c[ccccc]}
            a & 0 & 1.4 & 0.2 & 1.3 & 1.2 \\
            b & 1.4 & 0 & 1.6 & \times & 0.4 \\
            c & 0.2 & 1.6 & 0 & 1.5 & 1.4 \\
            d & 1.3 & \times & 1.5 & 0 & 0.3 \\
            e & 1.2 & 0.4 & 1.4 & 0.3 & 0 \\
          \end{block}
        \end{blockarray}
        \quad
        \implies
        \quad
        \begin{blockarray}{cccccc}
          & a & b & c & d & e \\
          \begin{block}{c[ccccc]}
            a & 0 & 1.4 & \boxed{0.2} & 1.3 & 1.2 \\
            b & 1.4 & 0 & 1.6 & \times & 0.4 \\
            c & \boxed{0.2} & 1.6 & 0 & 1.5 & 1.4 \\
            d & 1.3 & \times & 1.5 & 0 & 0.3 \\
            e & 1.2 & 0.4 & 1.4 & 0.3 & 0 \\
          \end{block}
        \end{blockarray}
      \end{align*}
    \item Merge: $\{b,d\}$ and $e$ since the distance between them is $0.3$.
      \begin{align*}
        \begin{blockarray}{cccccc}
          & a & b & c & d & e \\
          \begin{block}{c[ccccc]}
            a & 0 & 1.4 & \times & 1.3 & 1.2 \\
            b & 1.4 & 0 & 1.6 & \times & 0.4 \\
            c & \times & 1.6 & 0 & 1.5 & 1.4 \\
            d & 1.3 & \times & 1.5 & 0 & 0.3 \\
            e & 1.2 & 0.4 & 1.4 & 0.3 & 0 \\
          \end{block}
        \end{blockarray}
        \quad
        \implies
        \quad
        \begin{blockarray}{cccccc}
          & a & b & c & d & e \\
          \begin{block}{c[ccccc]}
            a & 0 & 1.4 & \times & 1.3 & 1.2 \\
            b & 1.4 & 0 & 1.6 & \times & 0.4 \\
            c & \times & 1.6 & 0 & 1.5 & 1.4 \\
            d & 1.3 & \times & 1.5 & 0 & \boxed{0.3} \\
            e & 1.2 & 0.4 & 1.4 & \boxed{0.3} & 0 \\
          \end{block}
        \end{blockarray}
      \end{align*}
    \item Merge: $\{a,c\}$ and $\{b,d,e\}$ since the distance between them is $1.2$.
      \begin{align*}
        \begin{blockarray}{cccccc}
          & a & b & c & d & e \\
          \begin{block}{c[ccccc]}
            a & 0 & 1.4 & \times & 1.3 & 1.2 \\
            b & 1.4 & 0 & 1.6 & \times & \times \\
            c & \times & 1.6 & 0 & 1.5 & 1.4 \\
            d & 1.3 & \times & 1.5 & 0 & \times \\
            e & 1.2 & \times & 1.4 & \times & 0 \\
          \end{block}
        \end{blockarray}
        \quad
        \implies
        \quad
        \begin{blockarray}{cccccc}
          & a & b & c & d & e \\
          \begin{block}{c[ccccc]}
            a & 0 & 1.4 & \times & 1.3 & \boxed{1.2} \\
            b & 1.4 & 0 & 1.6 & \times & \times \\
            c & \times & 1.6 & 0 & 1.5 & 1.4 \\
            d & 1.3 & \times & 1.5 & 0 & \times \\
            e & \boxed{1.2} & \times & 1.4 & \times & 0 \\
          \end{block}
        \end{blockarray}
      \end{align*}
    \item Draw the dendrogram dude
      \begin{align*}
        \includegraphics[width=0.4\textwidth]{images/dendrogram.png}
      \end{align*}
  \end{enumerate}
}
\subsection{Closeness}
\includegraphics[width=0.7\textwidth]{images/linkage.png}
\begin{itemize}
  \item Single linkage can lead to long chained clusters
  \item Complete linkage finds more compact clusters
  \item Average linkage is used less because it is computationally expensive
\end{itemize}
\section{Silhouette Score}
\begin{itemize}
  \item A measure of how similar an object is to its own cluster compared to other clusters
  \item Ranges from -1 to 1 with 1 being the best
  \item A score of 1 means the object is well matched to its own cluster and poorly matched to neighboring clusters
  \item A score of 0 means the object is on the boundary of two clusters (which is ambiguous)
  \item A score of -1 means the object is probably in the wrong cluster
\end{itemize}
\begin{align*}
  \includegraphics[width=0.4\textwidth]{images/silscore.png}
\end{align*}
\subsection{Bois and Gurls to Write Down}
Let $i$ be a point in a cluster. Then
\begin{itemize}
  \item $a(i)$: The average distance (dissimilarity) between $i$ and all other points in the same cluster (minimize $a$)
  \item $b(i)$: The minimum average distance between $i$ and all points in any other cluster (maximize $b$)
  \item Once we have $a$ and $b$, we can calculate the silhouette score by
    \begin{align*}
      s(i) &= \frac{b(i) - a(i)}{\max(a(i), b(i))}
    \end{align*}
\end{itemize}
\subsection{Walkthrough}
\ex{}{
  Compute the silhouette scores for each point, each cluster, and the overall score for the following:
  \begin{align*}
    \begin{tabular}{|c|c|c|c|}
      \hline
      Cluster & Point & $x$ & $y$ \\
      \hline
      1 & a & 0.8 & 0.7 \\
      1 & b & 0.9 & 0.8 \\
      \hline
      2 & c & 0.6 & 0.6 \\
      2 & d & 0 & 0.2 \\
      2 & e & 0.2 & 0.1 \\
      \hline
    \end{tabular}
  \end{align*}
  \nt{\textbf{I would highly recommend making an adjacency matrix for easy calculation.}}
}
\sol{}{
  I recommend drawing a table and filling it out. Here's what it should look like:
  \begin{align*}
    \begin{tabular}{|c|c|c|c|c|c|c|}
      \hline
      Cluster & Point & $x$ & $y$ & $a(i)$ & $b(i)$ & s(i) \\
      \hline
      1 & a & 0.8 & 0.7 & 0.2 & 0.93 & 0.785 \\
      1 & b & 0.9 & 0.8 & 0.2 & 1.13 & 0.832 \\
      \hline
      2 & c & 0.6 & 0.6 & 0.95 & 0.4 & -0.579 \\
      2 & d & 0 & 0.2 & 0.65 & 1.4 & 0.536 \\
      2 & e & 0.2 & 0.1 & 0.6 & 1.3 & 0.538 \\
      \hline
    \end{tabular}
  \end{align*}
  I'll walk through two points, $a$ and $c$.
  \begin{align*}
    a(a) &= \frac{0.1 + 0.1}{1} & \quad a(c) &= \frac{1 + 0.9}{2} \\
         &= 0.2 & \quad &= 0.95\\
    b(a) &= \frac{0.3 + 1.3 + 1.2}{3} & \quad b(c) &= \frac{0.5 + 0.3}{2} \\
         &= 0.93 & \quad &= 0.4 \\
    s(a) &= \frac{0.93 - 0.2}{\max(0.2, 0.93)} & \quad s(c) &= \frac{0.4 - 0.95}{\max(0.95, 0.4)} \\
         &= \frac{0.73}{0.93} & \quad &= \frac{-0.56}{0.95} \\
         &\approx 0.785 & \quad &\approx -0.579
  \end{align*}
  Now take the average of each cluster for the cluster scores:
  \begin{align*}
    s(1) &= \frac{0.785 + 0.832}{2} \approx 0.804 \\
    s(2) &= \frac{-0.579 + 0.536 + 0.538}{3} \approx 0.165
  \end{align*}
  Finally, take the average of the cluster scores for the overall score:
  \begin{align*}
    s &= \frac{0.785 + 0.832 - 0.579 + 0.536 + 0.538}{5} \approx 0.421
  \end{align*}
}


\chapter{Reinforcement Learning}
Variation of supervised learning where the algorithm learns to make decisions by interacting with its environment. The goal is to learn a policy that maps states to actions. Trial and error.

\section{RL Basics}
\begin{itemize}
  \item \textit{Agent:} The learner or decision maker
  \item \textit{Environment:} The world the agent interacts with
  \item \textit{State:} A representation of the environment
  \item \textit{Action:} A decision made by the agent from a subset of possible actions
  \item \textit{Reward:} A scalar feedback signal
  \item \textit{Discount Factor:} A value between 0 and 1 that determines the importance of future rewards
  \item \textit{Policy:} A strategy that the agent uses to determine its actions
  \item \textit{Value Function:} A prediction of future rewards
\end{itemize}

\section{Q-Learning}
\begin{itemize}
  \item A model-free reinforcement learning algorithm
  \item Try a possible action, observe the reward, and update the Q-value
  \item In the real world, the system can't see the reward states
\end{itemize}

This all boils down to this bad boi, which you should write down:
\begin{align*}
  Q(s, a) &= r(s,a) + \gamma \max_{a'} Q(s', a')
\end{align*}
\nt{To make life easier and convergence faster, always ask yourself "Can I reasonably assume the max Q value leaving a state?" If the answer is yes, then go ahead and use the max Q value.}
\subsection{Walkthrough}
\ex{}{
  Assume a discount factor of $0.6$. Give the optimal Q-values for the following environment:
  \begin{align*}
    \includegraphics[width=0.2\textwidth]{images/s0.png}
  \end{align*}
}
\sol{}{
  \begin{enumerate}
    \item Start with the Q-values going into the reward state because the max Q-value leaving is $0$.
      \begin{align*}
        \includegraphics[width=0.2\textwidth]{images/s1.png} \\
        Q_1 = Q_2 = 10 + 0.6 \cdot 0 = 10
      \end{align*}
      Note that we know $Q_1$ and $Q_2$ are the max Q-values leaving their respective states.
    \item Use $Q_1$ and $Q_2$ to as max Q-values.
      \begin{align*}
        \includegraphics[width=0.2\textwidth]{images/s2.png} \\
        Q_3 = Q_4 = 0 + 0.6 \cdot 10 = 6
      \end{align*}
      Note that we know $Q_3$ and $Q_4$ are the max Q-values leaving their respective states.
    \item Use $Q_3$ and $Q_4$ to as max Q-values.
      \begin{align*}
        \includegraphics[width=0.2\textwidth]{images/s3.png} \\
        Q_5 = Q_6 = -3 + 0.6 \cdot 6 = 0.60
      \end{align*}
    \item Bask in the glory of your optimal Q-values.
  \end{enumerate}
}
\chapter{CNNs}
Typically used for image recognition, CNNs are a type of neural network that uses convolutional layers to \textit{spatial and temporal dependencies} in the input data. They are made up of convolutional layers, pooling layers, and fully connected layers.
\section{Structure}
\begin{align*}
  \includegraphics[width=0.9\textwidth]{images/cnn.png}
\end{align*}
\subsection{Convolutional Layers}
This type of layer applies a convolution operation to the input, passing the result to the next layer. The convolution operation is defined by a kernel, which is a small matrix applied to the input. The kernel slides over the input, applying the operation to each region.
\begin{align*}
  \includegraphics[width=0.4\textwidth]{images/conv_layer.png} \\
\end{align*}
In the case of color images, the kernel is applied to each color channel.
\begin{align*}
  \includegraphics[width=0.6\textwidth]{images/rgb.png}
\end{align*}
\begin{itemize}
  \item \textit{Stride:} The number of pixels the kernel moves each time
  \item \textit{Padding:} Adding zeros to the input to preserve the spatial dimensions
  \item The weights of the kernel are learned during training
\end{itemize}
\subsection{Pooling Layers}
These bad bois reduce the spatial dimensions of the input. They do this by applying an operation to each region of the input. The most common operations are max pooling and average pooling. This decreases the computational power required to process the data. It also can extract \textit{dominant features}.
\begin{align*}
  \includegraphics[width=0.4\textwidth]{images/pooling.png}
\end{align*}
\subsubsection{Max Pooling}
\begin{itemize}
  \item Takes the maximum value from each region of the input
  \item Tends to perform better than average pooling
  \item Reduces the spatial dimensions along with de-noising the input
  \item Extracts dominant features
\end{itemize}
\subsubsection{Average Pooling}
\begin{itemize}
  \item Takes the average value from each region of the input
  \item Reduces the spatial dimensions
\end{itemize}
\subsection{Fully Connected Layers}
\begin{itemize}
  \item The final layer of the CNN
  \item Each neuron is connected to every neuron in the previous layer
  \item Typically used with softmax activation for image classification
  \item Feature maps are flattened into a vector
\end{itemize}
\section{AlexNet}
\begin{itemize}
  \item Introduced ``deep'' convolutions
  \item Used ReLU activation
  \item Good starting place for CNN architectures
\end{itemize}
\section{ResNet}
A type of deep learning architecture that uses residual connections to make training easier. The idea is that the network can learn the residual (difference) between the input and the output. This makes it easier to train deeper networks.
\begin{itemize}
  \item \textbf{Problem:} As the network gets deeper, it becomes harder to train. The accuracy can saturate and then degrade.
  \item \textbf{Residual Learning}: ResNet solves this problem by introducing residual learning. Instead of learning the underlying mapping directly, ResNet learns the residual function, which is the difference between the input and the desired output.
  \item \textbf{Residual Block}: The building block of ResNet is the residual block. It consists of a series of layers and a skip connection (shortcut) that bypasses these layers. The output of the residual block is the sum of the learned residual function and the input.
  \item \textbf{Skip Connection}: The skip connection is a key component of the residual block. It skips one or more layers and directly connects the input to the output of the block. This allows the gradients to flow directly through the network, making it easier to train deep networks. 
\end{itemize}
\subsection{Something to Be Grateful For}
The fact that you didn't have to calculate the dimensions and number of trainable parameters in a CNN :D

\chapter{Other Deep Learning Topics}
\section{GANs}
\begin{align*}
  \includegraphics[width=0.9\textwidth]{images/gan.png}
\end{align*}
\begin{itemize}
  \item \textit{Generator:} Generates fake data
    \begin{itemize}
      \item Tries to fool the discriminator
      \item Takes random noise as input (produces variety)
      \item Adjusts the weights based on the feedback from the discriminator
    \end{itemize}
    \item \textit{Discriminator:} Determines if the data is real or fake
      \begin{itemize}
        \item Tries to distinguish between real and fake data
        \item Adjusts the weights based on accuracy of predictions
      \end{itemize}
    \item Unsupervised learning since there is no labeled data (the discriminator learns from the generator)
    \item The generator and discriminator are trained simultaneously
\end{itemize}
\section{Sequential Models}
Often, we deal with sequential data, such as time series data, text data, and audio data. Sequential models are designed to handle this type of data.
\subsection{RNNs}
\begin{align*}
  \includegraphics[width=0.9\textwidth]{images/rnn.png}
\end{align*}
\begin{itemize}
  \item Allows outputs to be fed back into the network
  \item Can handle variable-length sequences
  \item \textit{Vanishing Gradient Problem:} The gradients can become very small, making it hard to learn long-term dependencies
  \item Single directional context
\end{itemize}
\subsection{LSTMs}
\begin{align*}
  \includegraphics[width=0.9\textwidth]{images/lstm.png}
\end{align*}
\begin{itemize}
  \item Solves the vanishing gradient problem by using gates
  \item \textit{Forget Gate:} Decides what information to throw away
  \item \textit{Input Gate:} Decides what information to store/update
  \item \textit{Output Gate:} Decides what the next hidden state should be
\end{itemize}
\subsection{Transformers}
Honestly, just go watch 3Blue1Brown's series on them lolol
\begin{itemize}
  \item \textit{Self-Attention:} Allows the model to weigh the importance of different words in a sentence
  \item \textit{Multi-Head Attention:} Allows the model to focus on different parts of the sentence and learn different representations
  \item \textit{Positional Encoding:} Adds positional information to the input embeddings
  \item \textit{Encoder-Decoder Architecture:} Used for tasks like translation
    \begin{itemize}
      \item The encoder processes the input sequence and produces a vector representation
      \item The decoder takes the vector representation and generates the output sequence
    \end{itemize}
  \item Underlying architecture of BERT, GPT, and other popular generative models
  \item Unsupservised learning
\end{itemize}
\end{document}
